# Test GitHub-based universe expansion

using Dates, Statistics

include("src/VolatilityAnomalyAnalysis.jl")
using .VolatilityAnomalyAnalysis
using .VolatilityAnomalyAnalysis.PortfolioAnalysis
using .VolatilityAnomalyAnalysis.PortfolioAnalysis.HistoricalConstituents

println("ğŸ§ª TESTING EXPANDED GITHUB-BASED UNIVERSE")
println("=" ^ 70)

# Test 1: Load GitHub data and check universe size
println("\n1ï¸âƒ£ Testing GitHub S&P 500 data loading...")

try
    # Test historical constituent retrieval with new approach
    test_dates = [Date(2000, 1, 1), Date(2008, 9, 1), Date(2020, 1, 1), Date(2024, 1, 1)]
    
    println("   ğŸ“… Testing historical constituents:")
    for test_date in test_dates
        constituents = HistoricalConstituents.get_historical_sp500_constituents(test_date)
        println("      $test_date: $(length(constituents)) constituents")
        
        # Check for key companies
        has_google = any(ticker -> ticker in ["GOOGL", "GOOG"], constituents)
        has_meta = any(ticker -> ticker in ["FB", "META"], constituents)  
        has_tesla = "TSLA" in constituents
        has_lehman = "LEH" in constituents
        has_enron = "ENE" in constituents
        has_amazon = "AMZN" in constituents
        
        println("         ğŸ“Š Key companies: Google:$(has_google ? "âœ…" : "âŒ") Meta:$(has_meta ? "âœ…" : "âŒ") Tesla:$(has_tesla ? "âœ…" : "âŒ") Lehman:$(has_lehman ? "âœ…" : "âŒ") Enron:$(has_enron ? "âœ…" : "âŒ") Amazon:$(has_amazon ? "âœ…" : "âŒ")")
    end
    
    println("   âœ… Historical constituent retrieval working with GitHub data")
    
catch e
    println("   âŒ Error testing GitHub constituents: $e")
    rethrow(e)
end

# Test 2: Build complete universe and validate expansion
println("\n2ï¸âƒ£ Testing complete universe building...")

try
    # Build universe for validation period  
    universe = HistoricalConstituents.build_point_in_time_universe(
        Date(2000, 1, 1), 
        Date(2024, 12, 31)
    )
    
    # Calculate universe statistics
    all_tickers = Set{String}()
    for constituents in values(universe)
        union!(all_tickers, constituents)
    end
    
    total_unique_tickers = length(all_tickers)
    avg_constituents = round(mean(length(v) for v in values(universe)), digits=1)
    max_constituents = maximum(length(v) for v in values(universe))
    min_constituents = minimum(length(v) for v in values(universe))
    
    println("   ğŸ“Š UNIVERSE STATISTICS:")
    println("      Total unique tickers: $total_unique_tickers")
    println("      Average constituents per month: $avg_constituents")
    println("      Max constituents: $max_constituents")
    println("      Min constituents: $min_constituents")
    println("      Total monthly snapshots: $(length(universe))")
    
    # Validation against expectation
    expected_range = 800:1200
    if total_unique_tickers in expected_range
        println("   âœ… VALIDATION PASSED: Universe size ($total_unique_tickers) in expected range ($expected_range)")
        validation_status = "PASSED"
    else
        println("   âš ï¸ VALIDATION WARNING: Universe size ($total_unique_tickers) outside expected range ($expected_range)")
        validation_status = "NEEDS_REVIEW"
    end
    
    # Sample some tickers to verify diversity
    sample_tickers = collect(all_tickers)[1:min(20, length(all_tickers))]
    println("   ğŸ“‹ Sample tickers: $(join(sample_tickers, ", "))")
    
    # Check for known historical companies
    historical_companies = ["LEH", "ENE", "GM", "YHOO", "AOL", "BSC", "WB", "KM"]
    found_historical = [ticker for ticker in historical_companies if ticker in all_tickers]
    
    println("   ğŸ›ï¸ Historical companies found: $(join(found_historical, ", "))")
    println("   ğŸ“ˆ Historical coverage: $(length(found_historical))/$(length(historical_companies)) ($(round(length(found_historical)/length(historical_companies)*100, digits=1))%)")
    
catch e
    println("   âŒ Error building complete universe: $e")
    rethrow(e)
end

# Test 3: Compare with old approach
println("\n3ï¸âƒ£ Comparing with previous limited approach...")

try
    # Get stats from new approach
    new_stats = HistoricalConstituents.get_universe_stats()
    
    println("   ğŸ“Š NEW GITHUB APPROACH:")
    println("      Total unique tickers: $(new_stats[:total_unique_tickers])")
    println("      Data source: $(new_stats[:data_source])")
    
    # Compare with old limited approach (estimated)
    old_estimated_tickers = 241  # From our previous Wikipedia-limited approach
    
    improvement_factor = round(new_stats[:total_unique_tickers] / old_estimated_tickers, digits=1)
    additional_tickers = new_stats[:total_unique_tickers] - old_estimated_tickers
    
    println("   ğŸ“Š COMPARISON:")
    println("      Old approach (limited): ~$old_estimated_tickers tickers")
    println("      New approach (GitHub): $(new_stats[:total_unique_tickers]) tickers")
    println("      Improvement factor: $(improvement_factor)x")
    println("      Additional tickers: +$additional_tickers")
    
    if improvement_factor >= 2.0
        println("   ğŸ¯ MAJOR IMPROVEMENT: Universe expanded by $(improvement_factor)x")
        improvement_status = "MAJOR"
    elseif improvement_factor >= 1.5
        println("   âœ… GOOD IMPROVEMENT: Universe expanded by $(improvement_factor)x")
        improvement_status = "GOOD"  
    else
        println("   âš ï¸ LIMITED IMPROVEMENT: Only $(improvement_factor)x expansion")
        improvement_status = "LIMITED"
    end
    
catch e
    println("   âŒ Error comparing approaches: $e")
end

# Test 4: Export for validation
println("\n4ï¸âƒ£ Exporting universe for manual validation...")

try
    export_df = HistoricalConstituents.export_universe("github_sp500_universe_validation.csv")
    
    println("   âœ… Exported universe to CSV for validation")
    println("   ğŸ“ File: github_sp500_universe_validation.csv")
    println("   ğŸ“Š Rows exported: $(nrow(export_df))")
    
    # Sample validation - show timeline for a known company
    sample_ticker = "AAPL"
    aapl_timeline = filter(row -> row.ticker == sample_ticker, export_df)
    
    if !isempty(aapl_timeline)
        first_date = minimum(aapl_timeline.date)
        last_date = maximum(aapl_timeline.date)
        total_months = length(aapl_timeline)
        
        println("   ğŸ $sample_ticker timeline validation:")
        println("      First appearance: $first_date")  
        println("      Last appearance: $last_date")
        println("      Total months: $total_months")
    end
    
catch e
    println("   âŒ Error exporting universe: $e")
end

println("\n" * ("=" ^ 70))
println("ğŸ¯ GITHUB UNIVERSE VALIDATION COMPLETE")

# Final summary
println("\nğŸ“‹ FINAL ASSESSMENT:")
if @isdefined(validation_status) && validation_status == "PASSED"
    println("âœ… Universe size validation: PASSED")
else
    println("âš ï¸ Universe size validation: NEEDS REVIEW")  
end

if @isdefined(improvement_status) && improvement_status in ["MAJOR", "GOOD"]
    println("âœ… Improvement over old approach: $(improvement_status)")
else
    println("âš ï¸ Improvement assessment: NEEDS REVIEW")
end

println("\nğŸš€ READY FOR FULL ANALYSIS:")
println("â€¢ Use expanded universe for bias-free volatility anomaly testing")
println("â€¢ Compare results with previous limited 241-ticker analysis")  
println("â€¢ Document impact of proper survivorship bias correction")
println("â€¢ Validate Novy-Marx critique with robust methodology")